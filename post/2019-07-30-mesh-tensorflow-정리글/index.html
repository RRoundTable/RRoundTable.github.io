<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>RoundTable  | mesh tensorflow 정리글</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.55.5" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="https://rroundtable.github.io/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="mesh tensorflow 정리글" />
<meta property="og:description" content="요약 batch-spliting이란, data-paralleism 방법론으로 분산화된 딥러닝 네트워크에서 많이 사용하며, Single-Program-Multiple-Data programing의 일종이다. 즉, 데이터가 클 때 분산시켜서 대처하는 방법론이라고 할 수 있다.
하지만, 모델이 한번에 RAM에 올리기 클 경우에는 어떻게 해야할까? 혹은 모델의 크기 때문에 작은 batch size를 사용할 때 발생하는 high latency와 비효율성이 발생한다면 어떻게 해야할까? 이를 해결하기 위해서는 Model-parallenism을 사용해야한다.
하지만, 효과적인 model-parallelism은 일반적으로 복잡한 편이다. 이런 문제를 간단하게 해결하기 위해서 Mesh-tensorflow를 제안한다. data-parallelism은 tensor와 operations를 batch dimension으로 나누는 것으로 치환한다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rroundtable.github.io/post/2019-07-30-mesh-tensorflow-%EC%A0%95%EB%A6%AC%EA%B8%80/" />
<meta property="article:published_time" content="2019-07-30T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-07-30T00:00:00&#43;00:00"/>

<meta itemprop="name" content="mesh tensorflow 정리글">
<meta itemprop="description" content="요약 batch-spliting이란, data-paralleism 방법론으로 분산화된 딥러닝 네트워크에서 많이 사용하며, Single-Program-Multiple-Data programing의 일종이다. 즉, 데이터가 클 때 분산시켜서 대처하는 방법론이라고 할 수 있다.
하지만, 모델이 한번에 RAM에 올리기 클 경우에는 어떻게 해야할까? 혹은 모델의 크기 때문에 작은 batch size를 사용할 때 발생하는 high latency와 비효율성이 발생한다면 어떻게 해야할까? 이를 해결하기 위해서는 Model-parallenism을 사용해야한다.
하지만, 효과적인 model-parallelism은 일반적으로 복잡한 편이다. 이런 문제를 간단하게 해결하기 위해서 Mesh-tensorflow를 제안한다. data-parallelism은 tensor와 operations를 batch dimension으로 나누는 것으로 치환한다.">


<meta itemprop="datePublished" content="2019-07-30T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-07-30T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="586">



<meta itemprop="keywords" content="deeplearning,engineering," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="mesh tensorflow 정리글"/>
<meta name="twitter:description" content="요약 batch-spliting이란, data-paralleism 방법론으로 분산화된 딥러닝 네트워크에서 많이 사용하며, Single-Program-Multiple-Data programing의 일종이다. 즉, 데이터가 클 때 분산시켜서 대처하는 방법론이라고 할 수 있다.
하지만, 모델이 한번에 RAM에 올리기 클 경우에는 어떻게 해야할까? 혹은 모델의 크기 때문에 작은 batch size를 사용할 때 발생하는 high latency와 비효율성이 발생한다면 어떻게 해야할까? 이를 해결하기 위해서는 Model-parallenism을 사용해야한다.
하지만, 효과적인 model-parallelism은 일반적으로 복잡한 편이다. 이런 문제를 간단하게 해결하기 위해서 Mesh-tensorflow를 제안한다. data-parallelism은 tensor와 operations를 batch dimension으로 나누는 것으로 치환한다."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://rroundtable.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      RoundTable
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://rroundtable.github.io/" title="Home page">
              Home
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://github.com/RRoundTable" title="Works page">
              Works
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://rroundtable.github.io/post/aboutme" title="About me page">
              About me
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://rroundtable.github.io/categories/index.html" title="Categories page">
              Categories
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://rroundtable.github.io/tags/index.html" title="Tags page">
              Tags
            </a>
          </li>
          
        </ul>
      
      



<a href="twitter_username" target="_blank" class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




<a href="linkedin_username" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="RRoundTable" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">mesh tensorflow 정리글</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2019-07-30T00:00:00Z">July 30, 2019</time>
      
      
    </header>
    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-three-thirds-l">

<h2 id="요약">요약</h2>

<p>batch-spliting이란, data-paralleism 방법론으로 분산화된 딥러닝 네트워크에서 많이 사용하며, Single-Program-Multiple-Data programing의 일종이다. 즉, 데이터가 클 때 분산시켜서 대처하는 방법론이라고 할 수 있다.</p>

<p>하지만, 모델이 한번에 RAM에 올리기 클 경우에는 어떻게 해야할까? 혹은 모델의 크기 때문에 작은 batch size를 사용할 때 발생하는 high latency와 비효율성이 발생한다면 어떻게 해야할까? 이를 해결하기 위해서는 Model-parallenism을 사용해야한다.</p>

<p>하지만, 효과적인 model-parallelism은 일반적으로 복잡한 편이다. 이런 문제를 간단하게 해결하기 위해서 Mesh-tensorflow를 제안한다. data-parallelism은 tensor와 operations를 batch dimension으로 나누는 것으로 치환한다.</p>

<h3 id="data-paralleism">Data-paralleism</h3>

<p>특징은 다음과 같다.</p>

<ul>
<li>각 core마다 복사되는 Parameters</li>
<li>core마다 분산되는 batch</li>
<li>sum(allreduce) parameters gradients</li>
</ul>

<p>장점은 다음과 같다.
-  보편적으로 사용되는 방식이다.
-  Compile 시간이 빠르다. (SPMD)
-  Full Utilization
-  locally-connected network조건하에서 allreduce가 빠르게 적용된다.</p>

<p>단점은 다음과 같다.
- 모든 parameters가 하나의 core에 실을 수 있어야 한다.</p>

<h3 id="transformer-lm-5b-parameters">Transformer LM - 5B Parameters</h3>

<p>Data-parellesim을 Transformer와 같은 큰 모델에 적용할 경우 문제가 발생한다. 각 core마다 모델 파라미터를 저장해야하는데, 이는 out-of-memory문제를 야기하거나 batch size를 크게 사용하지 못하는 상황이 발생한다.</p>

<h3 id="model-paralleism">Model-paralleism</h3>

<p>장점은 다음과 같다.</p>

<ul>
<li>거대한 모델을 학습시킬 수 있다.</li>
<li>potentially low latency</li>
</ul>

<p>단점은 다음과 같다.
- 적용하기 힘들다.</p>

<h2 id="mesh-tensorflow">Mesh-Tensorflow</h2>

<p>Mesh-Tensorflow의 장점은 다음과 같다.</p>

<ul>
<li>Every processor involved in every operation.</li>
<li>Single Program Multiple Devices(SPMD)</li>
<li>collective communication (like allreduce)</li>
</ul>

<p>Mesh-Tensorflow에서는 다음과 같은 역할을 하고자 한다.</p>

<ol>
<li>Data-parallelism (batch-spliting)</li>
<li>Model-parallelism(model-spliting)</li>
<li>Spatial Spliting of large inputs</li>
<li>Combinations of these</li>
</ol>

<p>적용되는 하드웨어는 아래와 같은 특징을 가진다.</p>

<ol>
<li>유사한 프로세서로 구성되어 있으며</li>
<li>n-dimensional mesh로 여길 수 있다</li>
<li>like multi-gpu, multi-cpu</li>
</ol>

<h4 id="user-defines-which-dimension-is-split">User defines which dimension is split</h4>

<p>Data-parallelism같은 경우에는 batch dimentsion을 가지고 분리한다.
- batch dimension이 있는 경우:  batch dimension으로 나눈다.
- batch dimension이 없는 경우: parameters를 복사한다.</p>

<p>Model-Paralleism같은 경우 위와 다른  dimension을 분리한다. 예를 들면, hidden layer size dimension이 있을 수 있다.</p>

<h4 id="where-does-communication-happen">Where does communication happen?</h4>

<p>대부분의 연산들은 같은 프로세서안에서의 input들의 조각을 계산한다. 하지만, allreduce처럼 다른 프로세서의 output에 대해서 연산을 해야할 때도 있다. 이 때 collective communication이 필요하다.</p>

<h2 id="case-study">Case Study</h2>

<p><img src="https://user-images.githubusercontent.com/27891090/62110969-8847a980-b2ea-11e9-9919-c216afaef8f0.png" style="width:70%;></p>

<p>위의 이미지는 간단한 뉴럴네트워크를 batch dimension기준으로 분리한 것이다. - data parreliesm</p>

<p><img src="https://user-images.githubusercontent.com/27891090/62111135-e70d2300-b2ea-11e9-97fd-6c3e15c6d395.png"  style="width:70%;">
위의 이미지는 hidden layer dimension을 기준으로 분리한 것이다.</p>

<p><img src="https://user-images.githubusercontent.com/27891090/62111660-00fb3580-b2ec-11e9-924d-49dd49652b6e.png"  style="width: 70%;">
위의 이미지는 data dimension을 기준으로 분리한 것이다.</p>

<p>아래의 이미지는 data-parallelism과 Model parallelism을 함께 구성한 것이다.</p>

<p><img src="https://user-images.githubusercontent.com/27891090/62111707-25efa880-b2ec-11e9-9f89-2a6efb23cda8.png" style="width: 70%;"></p>

<h3 id="layout-for-transformer-model">Layout for Transformer Model</h3>

<p><img src="https://user-images.githubusercontent.com/27891090/62111937-a31b1d80-b2ec-11e9-95e5-2ee93cd3a49d.png" style="width: 70%;"></p>

<h3 id="picking-a-good-layout">Picking a Good Layout</h3>

<ul>
<li>반복되는 업무를 피하기 위해서, 연산량이 많은 matmul/einsum은 모든 mesh dimension에 따라서 분리되어야 한다.</li>
<li>같은 tensor에서 두가지 종류의 dimension으로 분리할 수 없다</li>
<li>너무 잘게 나누면 communication 비용이 올라가므로 유의해야한다.</li>
</ul>

<h2 id="example">Example</h2>

<ul>
<li>Describing the mathematical operations</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># tf_images is a tf.Tensor with shape [100, 28, 28] and dtype tf.float32</span>
<span style="color:#75715e"># tf_labels is a tf.Tensor with shape [100] and dtype tf.int32</span>
<span style="color:#f92672">import</span> mesh_tensorflow <span style="color:#f92672">as</span> mtf

graph <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Graph()
mesh <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Mesh(graph, <span style="color:#e6db74">&#34;my_mesh&#34;</span>)
batch_dim <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Dimension(<span style="color:#e6db74">&#34;batch&#34;</span>, <span style="color:#ae81ff">100</span>)
rows_dim <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Dimension(<span style="color:#e6db74">&#34;rows&#34;</span>, <span style="color:#ae81ff">28</span>)
cols_dim <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Dimension(<span style="color:#e6db74">&#34;cols&#34;</span>, <span style="color:#ae81ff">28</span>)
hidden_dim <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Dimension(<span style="color:#e6db74">&#34;hidden&#34;</span>, <span style="color:#ae81ff">1024</span>)
classes_dim <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Dimension(<span style="color:#e6db74">&#34;classes&#34;</span>, <span style="color:#ae81ff">10</span>)
images <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>import_tf_tensor(
    mesh, tf_images, shape<span style="color:#f92672">=</span>[batch_dim, rows_dim, cols_dim])
labels <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>import_tf_tensor(mesh, tf_labels, [batch_dim])
w1 <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>get_variable(mesh, <span style="color:#e6db74">&#34;w1&#34;</span>, [rows_dim, cols_dim, hidden_dim])
w2 <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>get_variable(mesh, <span style="color:#e6db74">&#34;w2&#34;</span>, [hidden_dim, classes_dim])

<span style="color:#75715e"># einsum is a generalization of matrix multiplication (see numpy.einsum)</span>
hidden <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>relu(mtf<span style="color:#f92672">.</span>einsum(images, w1, output_shape<span style="color:#f92672">=</span>[batch_dim, hidden_dim]))
logits <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>einsum(hidden, w2, output_shape<span style="color:#f92672">=</span>[batch_dim, classes_dim])
loss <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>reduce_mean(mtf<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>softmax_cross_entropy_with_logits(
    logits, mtf<span style="color:#f92672">.</span>one_hot(labels, classes_dim), classes_dim))
w1_grad, w2_grad <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>gradients([loss], [w1, w2])
update_w1_op <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>assign(w1, w1 <span style="color:#f92672">-</span> w1_grad <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.001</span>)
update_w2_op <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>assign(w2, w2 <span style="color:#f92672">-</span> w2_grad <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.001</span>)</code></pre></div>
<ul>
<li>Describing tensor/computation layout: data-parallelism</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">devices <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;gpu:0&#34;</span>, <span style="color:#e6db74">&#34;gpu:1&#34;</span>, <span style="color:#e6db74">&#34;gpu:2&#34;</span>, <span style="color:#e6db74">&#34;gpu:3&#34;</span>]
mesh_shape <span style="color:#f92672">=</span> [(<span style="color:#e6db74">&#34;all_processors&#34;</span>, <span style="color:#ae81ff">4</span>)] 
layout_rules <span style="color:#f92672">=</span> [(<span style="color:#e6db74">&#34;batch&#34;</span>, <span style="color:#e6db74">&#34;all_processors&#34;</span>)] <span style="color:#75715e"># batch dimension을 각 gpu의 개수만큼 분산</span>
mesh_impl <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>placement_mesh_impl<span style="color:#f92672">.</span>PlacementMeshImpl(
    mesh_shape, layout_rules, devices)
lowering <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Lowering(graph, {mesh:mesh_impl})
tf_update_ops <span style="color:#f92672">=</span> [lowering<span style="color:#f92672">.</span>lowered_operation(update_w1_op),
                 lowering<span style="color:#f92672">.</span>lowered_operation(update_w2_op)]</code></pre></div>
<ul>
<li>Alternatively model-parallelism</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">devices <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;gpu:0&#34;</span>, <span style="color:#e6db74">&#34;gpu:1&#34;</span>, <span style="color:#e6db74">&#34;gpu:2&#34;</span>, <span style="color:#e6db74">&#34;gpu:3&#34;</span>]
mesh_shape <span style="color:#f92672">=</span> [(<span style="color:#e6db74">&#34;processor_rows&#34;</span>, <span style="color:#ae81ff">2</span>), (<span style="color:#e6db74">&#34;processor_cols&#34;</span>, <span style="color:#ae81ff">2</span>)] <span style="color:#75715e"># modified</span>
layout_rules <span style="color:#f92672">=</span> [(<span style="color:#e6db74">&#34;batch&#34;</span>, <span style="color:#e6db74">&#34;processor_rows&#34;</span>), (<span style="color:#e6db74">&#34;hidden&#34;</span>, <span style="color:#e6db74">&#34;processor_cols&#34;</span>)] <span style="color:#75715e"># modified, row * col 사각형 형태의 mesh 형성</span>
mesh_impl <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>placement_mesh_impl<span style="color:#f92672">.</span>PlacementMeshImpl(
    mesh_shape, layout_rules, devices)
lowering <span style="color:#f92672">=</span> mtf<span style="color:#f92672">.</span>Lowering(graph, {mesh:mesh_impl})
tf_update_ops <span style="color:#f92672">=</span> [lowering<span style="color:#f92672">.</span>lowered_operation(update_w1_op),
                 lowering<span style="color:#f92672">.</span>lowered_operation(update_w2_op)]</code></pre></div>
<h3 id="reference">Reference</h3>

<ul>
<li><a href="https://www.youtube.com/watch?v=HgGyWS40g-g">https://www.youtube.com/watch?v=HgGyWS40g-g</a></li>
<li><a href="https://github.com/tensorflow/mesh">https://github.com/tensorflow/mesh</a></li>
<li><a href="https://arxiv.org/abs/1811.02084">https://arxiv.org/abs/1811.02084</a></li>
</ul>
<ul class="pa0">
  
   <li class="list">
     <a href="https://rroundtable.github.io/tags/deeplearning" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">deeplearning</a>
   </li>
  
   <li class="list">
     <a href="https://rroundtable.github.io/tags/engineering" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">engineering</a>
   </li>
  
</ul>
<div class="mt6">
      
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "disqus_shortname" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
      </div>
    </section>
  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://rroundtable.github.io/" >
    &copy; 2019 RoundTable
  </a>
    <div>



<a href="twitter_username" target="_blank" class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




<a href="linkedin_username" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="RRoundTable" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




</div>
    <div><script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script></div>
    <div>




</div>
  </div>
</footer>

    

  <script src="https://rroundtable.github.io/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
