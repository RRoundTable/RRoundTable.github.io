<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>RoundTable  | Mixup 정리글</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.55.5" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="https://rroundtable.github.io/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="Mixup 정리글" />
<meta property="og:description" content="Mixup: Beyond Empirical Risk Minimization mixup은 deep learning model의 memorization문제나 adversarial examples에 민감한 이슈를 해결하기 위해 나온 Data Augmentation기법입니다.
 memorization:  모델이 학습을 진행할 때, 정답만을 기억하고 내리는 행동. 즉, 데이터 분포를 학습하는 것이 아니라 해당 데이터가 어떤 라벨에 해당하는지 기억하게 되는 것. 결론적으로는 test distribution에 대한 generalization을 하지 못한다.
 sensitivity to adversarial examples: adversarial attack에 취약하다.  mixup은 network를 data pair간의 convex combination을 이용하여 학습시킵니다. 이는 결과적으로 모델이 training sample간에 simple linear behavior를 하지 않도록 하는 효과가 있습니다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rroundtable.github.io/post/mixup-467e0a5d-4d28-4e05-a587-9007b9d1b97f/" />
<meta property="article:published_time" content="2019-07-21T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-07-21T00:00:00&#43;00:00"/>

<meta itemprop="name" content="Mixup 정리글">
<meta itemprop="description" content="Mixup: Beyond Empirical Risk Minimization mixup은 deep learning model의 memorization문제나 adversarial examples에 민감한 이슈를 해결하기 위해 나온 Data Augmentation기법입니다.
 memorization:  모델이 학습을 진행할 때, 정답만을 기억하고 내리는 행동. 즉, 데이터 분포를 학습하는 것이 아니라 해당 데이터가 어떤 라벨에 해당하는지 기억하게 되는 것. 결론적으로는 test distribution에 대한 generalization을 하지 못한다.
 sensitivity to adversarial examples: adversarial attack에 취약하다.  mixup은 network를 data pair간의 convex combination을 이용하여 학습시킵니다. 이는 결과적으로 모델이 training sample간에 simple linear behavior를 하지 않도록 하는 효과가 있습니다.">


<meta itemprop="datePublished" content="2019-07-21T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-07-21T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="808">



<meta itemprop="keywords" content="deeplearning,safet,augmentation," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Mixup 정리글"/>
<meta name="twitter:description" content="Mixup: Beyond Empirical Risk Minimization mixup은 deep learning model의 memorization문제나 adversarial examples에 민감한 이슈를 해결하기 위해 나온 Data Augmentation기법입니다.
 memorization:  모델이 학습을 진행할 때, 정답만을 기억하고 내리는 행동. 즉, 데이터 분포를 학습하는 것이 아니라 해당 데이터가 어떤 라벨에 해당하는지 기억하게 되는 것. 결론적으로는 test distribution에 대한 generalization을 하지 못한다.
 sensitivity to adversarial examples: adversarial attack에 취약하다.  mixup은 network를 data pair간의 convex combination을 이용하여 학습시킵니다. 이는 결과적으로 모델이 training sample간에 simple linear behavior를 하지 않도록 하는 효과가 있습니다."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://github.com/RRoundTable/mixup_keras/raw/master/results/sample%5B5%5D_%5B4%5D.gif');">
    <div class="pb3-m pb6-l bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://rroundtable.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      RoundTable
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://rroundtable.github.io/" title="Home page">
              Home
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://github.com/RRoundTable" title="Works page">
              Works
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://rroundtable.github.io/post/aboutme" title="About me page">
              About me
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://rroundtable.github.io/categories/index.html" title="Categories page">
              Categories
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://rroundtable.github.io/tags/index.html" title="Tags page">
              Tags
            </a>
          </li>
          
        </ul>
      
      



<a href="twitter_username" target="_blank" class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




<a href="linkedin_username" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="RRoundTable" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Mixup 정리글</h1>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">Mixup 정리글</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2019-07-21T00:00:00Z">July 21, 2019</time>
      
      
    </header>
    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-three-thirds-l">

<h1 id="mixup-beyond-empirical-risk-minimization">Mixup: Beyond Empirical Risk Minimization</h1>

<p><strong>mixup은 deep learning model의 memorization문제나 adversarial examples에 민감한 이슈를 해결하기 위해 나온 Data Augmentation기법입니다.</strong></p>

<ul>
<li>memorization:</li>
</ul>

<p>모델이 학습을 진행할 때, 정답만을 기억하고 내리는 행동.
즉, 데이터 분포를 학습하는 것이 아니라 해당 데이터가 어떤 라벨에 해당하는지 기억하게 되는 것.
<em>결론적으로는 test distribution에 대한 generalization을 하지 못한다.</em></p>

<ul>
<li>sensitivity to adversarial examples: adversarial attack에 취약하다.</li>
</ul>

<p><strong>mixup은 network를 data pair간의 convex combination을 이용하여 학습시킵니다. 이는 결과적으로 모델이 training sample간에 simple linear behavior를 하지 않도록 하는 효과가 있습니다.</strong></p>

<ul>
<li>simple linear behavior between training examples:</li>
</ul>

<h2 id="empirical-risk-minimization-erm-vs-vicinal-risk-minimization-vrm">Empirical Risk Minimization(ERM) VS Vicinal Risk Minimization(VRM)</h2>

<p><strong>[성공적인 neural networks의 두 가지 특징]</strong></p>

<ol>
<li><p>trained as to minimize their average error over the training data.</p></li>

<li><p>the size of neural networks scales linearly with the number of training examples.</p></li>
</ol>

<p>하지만, learning thoery에 따르면 ERM의 수렴은 모델의 복잡도가 데이터의 수보다 크지 않을 때 보장된다. 이는 [2]번 조건과 모순되어 보일 수 있으나 overfitting issue를 고려해보면 이해가 된다.</p>

<p><strong>[memorization의 측정]</strong>
adversarial examples에 예측하는 라벨이 크게 변하는 정도가 클수록 memorization이 크다고 평가할 수 있다.
직관적으로 생각해보면, 사람의 지각으로는 큰 차이가 없는 데이터에 대해서 딥러닝 모델이 서로 다른 예측을 한다면 이는 generalization을 못한 것으로 평가할 수 있다.</p>

<p><strong>[Vicinial Risk Minimization이란]</strong>
data augmentation의 이론적 배경으로 training data와 유사한 주변 데이터를 묘사하는 것이다.
이것이 가능해지면, virtual example(만들어진 데이터)는 training distribution의 support를 확대하는 효과를 가져온다.
(training distribution중 모호한 부분을 채워주는 것으로 해석)</p>

<p>참고: <a href="https://wikidocs.net/17374">[support of distribution]</a></p>

<h2 id="contribution">Contribution</h2>

<p>$$X_{new} = {\lambda}X_i + (1 - {\lambda})X_j$$</p>

<p>$$Y_{new} = {\lambda}Y_i + (1 - {\lambda})Y_j$$</p>

<p>위의 수식대로 data augmentation을 하는 것이 mixup의 전부이다.</p>

<p>아래의 영상은 lambda값에 따라서 mixup 데이터의 pca결과값이 어떻게 변하는지 시각화한 것이다. 아래의 그림들처럼 linear하게 PCA value가 변하는 것을 확인하였는데 이는 VRM 가정이 옳다는 것을 보여준다.</p>

<p><center>
<img src="https://github.com/RRoundTable/mixup_keras/raw/master/results/sample1_3.gif" style="width: 60%;"></p>

<p><img src="https://github.com/RRoundTable/mixup_keras/raw/master/results/sample%5B5%5D_%5B4%5D.gif" style="width: 60%;"></p>

<p><img src="https://github.com/RRoundTable/mixup_keras/raw/master/results/sample6_3.gif" style="width: 60%;">
</center></p>

<h2 id="from-empirical-risk-minimization-to-mixup">From Empirical Risk Minimization To Mixup</h2>

<p>Supervised learning에서의 task는 결국 random feature vector X와 random target vector Y간의 관계를 설명할 수 있는 함수 f를 찾는 것이다. 함수 f는 joint distribution P(X, Y)를 따른다.
이 때, loss function의 역할은 prediction f(X)와 target Y간의 차이를 나타내며 학습을 진행하면서 average loss를 감소시킨다. 여기서 average loss는 <strong><em>expected risk</em></strong>으로 해석된다.
이를 수식으로 나타내면 아래와 같다.</p>

<p>$${R}(f) = \int {loss}({f}(x), y)dP(x,y)\ \ [1]$$</p>

<p>하지만, distribution P는 실제상황에서 알기 힘들다. (intractable distribution)
이를 해결하기 위해서 <strong><em>empricial distribution</em></strong>으로 근사하는 방법론을 이용한다. 이를 수식으로 나타내면 아래와 같다.</p>

<p>$${P}<em>{\sigma}=\frac{1}{n}\Sigma</em>{i=1}^{n}\sigma(x={x}_i, y={y}_i) \ \ [2]$$</p>

<p>$$\sigma(x={x}_i, y={y}_i) 는\ Dirac\ mass\ centered \ at\ (x_i, y_i)\ 성질을 가지고 있다.   $$</p>

<p>[1]수식에 [2]수식을 대입하면 아래와 같이 전개될 수 있다.</p>

<p>참고: <a href="https://en.wikipedia.org/wiki/Dirac_delta_function">Dirac mass centered</a>
아래 그림과 같이 굉장히 naive한 가정이다.</p>

<p><center></p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Dirac_distribution_PDF.svg/325px-Dirac_distribution_PDF.svg.png" style="width:50%;"></p>

<p></center></p>

<p><code>$$R_{\sigma}=\int loss(f(x), y)dP_{\sigma}(x,y)=\frac{1}{n}\Sigma_{i=1}^{n}loss(f(x_i),y_i)$$</code></p>

<p>위와 같이 ERM은 간단하게 계산될 수 있지만, Memorization이라는 현상을 야기할 수 있다.
joint distribution P에 어떤 가정을 하느냐에 따라서 결과가 달라질 수 있는데 이 논문에서는 <strong>Vicinal Risk Minimization Principle</strong>을 적용하고 있다.
VRM을 가정하게 되면 P는 다음과 같이 정의할 수 있다.</p>

<p><code>$$P_v(\tilde{x}, \tilde{y})=\frac{1}{n}\Sigma_{i=1}^{n}V(\tilde{x}, \tilde{y}|x_i, y_i) \ \ where \ v\ is \ a \ \ a \ \ vicinity \ distribution$$</code></p>

<p>vicinity distribution은 만들어낸 feature-target pair의 probability를 측정한다. 즉, 얼마나 그럴듯한 데이터인지 판단하는 것이다.</p>

<p><strong>[what is mixup doing?]</strong></p>

<p><img src="https://pic4.zhimg.com/v2-eac38dd1863c1d26f547bb91d04fe924_1200x500.jpg" alt="" /></p>

<p>Figure 1 (b) Effect of mixup on a toy problem.
Green: Class 0
Orrange: Class 1
Blue shading indicates P(y = 1| x).</p>

<p>위의 그림을 통해서 할 수 있듯이, mixup은 uncertainty를 측정하는데 더 효과적이다.
파란색 부분은 해당 데이터 x가 주어졌을 때, Class 1일 확률이다. ERM을 보면 파란색 부분이 Class 1가 가까운 것과 가깝지 않는 것 사이의 차이를 나타내지 못한다.
반면에 mixup은 가까운 부분은 더 짙은 파란색으로 나타내어, uncertainty를 smoother하게 측정할 수 있다.</p>

<p><img src="https://user-images.githubusercontent.com/27891090/61589051-ef28dc80-abdf-11e9-9650-b8cfca8e59a0.jpg"></p>

<p>(a) 는 prediction을 나타낸 것이고, (b)는 gradient norm을 나타낸 것이다.
(a)를 보면 mixup으로 학습시킨 것이 더 prediction측면에서 좋은 성능을 보이고 있다.</p>

<p>한편, (b)를 보면 gradient norm이 더 작게 나는 것을 알 수 있는데, 이는 더 안정적인 학습을 보이고 있다는 것을 보여준다.</p>

<p>참고: norm
- 일반적으로 크기 혹은 길이를 나타낸다.</p>

<h2 id="실험결과">실험결과</h2>

<p><strong>[3.1 IMAGENET CLASSIFICATION]</strong>
evaluation과정에서 224 * 224 크기의 중간부분이 소실된 이미지를 test하였다.  실험결과 hyperparameter alpha는 0.1에서 0.4사이의 값이 우수한 성능을 보였으며, alpha값이 이보다 더 크면 underfitting의 부작용을 가져왔다. 또한 mixup은 higer capacities와 longer training run의 효과를 가져왔다. 이는 ERM과 비교했을 때 , epoch 90에서 mixup이 더 큰 성능개선효과를 보였다는 것으로 증명하였다.</p>

<p><strong>[3.2 CIFAR10 AND CIFAR100]</strong></p>

<p><img src="https://user-images.githubusercontent.com/27891090/61589071-24cdc580-abe0-11e9-8fdd-9575261c1d15.png"></p>

<p>실험결과: imagenet</p>

<p><strong>[3.3 SPEECH DATA]</strong></p>

<p><img src="https://user-images.githubusercontent.com/27891090/61589086-50e94680-abe0-11e9-8d39-7ee284126604.png"></p>

<p><strong>[3.4 MEMORIZATION OF CORRUPTED LABELS]</strong></p>

<p><img src="https://user-images.githubusercontent.com/27891090/61589115-986fd280-abe0-11e9-805a-f546f7531bc8.png"></p>

<p>mixup interpolation alpha가 더 커질수록 memorization이 더 어려워진다는 가설을 세웠다.
corruption label을 가지고 학습을 시켰다. 이는 memorizaiton을 검증하는 실험에서 사용된다. (더 찾아보기)
실험결과 test과정에서 large alpha가 dropout(0.7, 0.8)보다 test error를 더 줄일 수 있었으며, real label에 대해서는 낮은 training error를 보이고 noisy label에 대해서는 높은 training error를 보였다. 주목할 점은 dropout과 mixup을 같이 사용했을 때 성능이 가장 좋았다.</p>

<p><strong>[3.5 ROBUSTNESS TO ADVERSARIAL EXAMPLES]</strong></p>

<p><img src="https://user-images.githubusercontent.com/27891090/61589119-acb3cf80-abe0-11e9-8b5c-12f60a21f108.png"></p>

<p><strong>[3.6 TABULAR DATA]</strong></p>

<p><img src="https://user-images.githubusercontent.com/27891090/61589126-c35a2680-abe0-11e9-8b30-21679d86d0e5.png"></p>

<p><strong>[3.7 STABILIZATION OF GENERATIVE ADVERSARIAL NETWORKS]</strong></p>

<p><img src="https://user-images.githubusercontent.com/27891090/61589135-d5d46000-abe0-11e9-97fa-96bd771c656c.png"></p>

<p>mixup은 disciriminator의 <strong>gradient regularizer</strong>의 역할을 하기 때문에, 더 안정적인 학습을 할 수 있다.</p>

<p><code>$$
\max_g\min_d E_{x,  z}\mathcal{l}(d(x), 1) + l(d(g(z)), 0)
$$</code></p>

<p>기존의 GAN objective</p>

<p>아래는 mixup이 적용된 <strong><em>GAN distriminator objective</em></strong>이다.</p>

<p><code>$$max_gmin_dE_{x, y, \lambda}l(d(\lambda x + (1-\lambda)g(z), \lambda).$$</code></p>

<p><strong>[3.8 ABLATION STUDIES]</strong></p>

<p>이 논문에서는 convex combination을 통한 data augmentation방법론을 제안했지만, 다양한 방법론이 있을 수 있다.
[예시]</p>

<ul>
<li>feature map을 섞는다.</li>
<li>같은 클레스의 데이터</li>
<li>비슷한 거리에 있는 데이터</li>
<li>다른 클레스의 데이터</li>
</ul>

<p>실험결과 현 논문에서 제시한 mixup이 제일 좋은 성능을 보였다.</p>
<ul class="pa0">
  
   <li class="list">
     <a href="https://rroundtable.github.io/tags/deeplearning" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">deeplearning</a>
   </li>
  
   <li class="list">
     <a href="https://rroundtable.github.io/tags/safet" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">safet</a>
   </li>
  
   <li class="list">
     <a href="https://rroundtable.github.io/tags/augmentation" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">augmentation</a>
   </li>
  
</ul>
<div class="mt6">
      
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "disqus_shortname" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
      </div>
    </section>
  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://rroundtable.github.io/" >
    &copy; 2019 RoundTable
  </a>
    <div>



<a href="twitter_username" target="_blank" class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




<a href="linkedin_username" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="RRoundTable" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




</div>
    <div><script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script></div>
    <div>




</div>
  </div>
</footer>

    

  <script src="https://rroundtable.github.io/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
